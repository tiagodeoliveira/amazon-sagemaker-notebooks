{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99803129",
   "metadata": {},
   "source": [
    "We start by installing all the necessary libraries and importing then to our notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "95392806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (1.17.99)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (5.0.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3) (0.4.2)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.99 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3) (1.20.99)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.99->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.99->boto3) (1.26.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.99->boto3) (1.15.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker) (0.59.0)\n",
      "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b5331613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import docker\n",
    "import pathlib\n",
    "import base64\n",
    "import time\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4ea9071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BASE_NAME = 'yolov5'\n",
    "YOLOV5_IMAGE_NAME = f'{MODEL_BASE_NAME}-sagemaker'\n",
    "SAGEMAKER_IMAGES_REGISTRY_ID = '763104351884'\n",
    "\n",
    "session = boto3.session.Session()\n",
    "aws_region = session.region_name\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity().get('Account')\n",
    "\n",
    "ecr_client = boto3.client('ecr')\n",
    "docker_client = docker.from_env()\n",
    "\n",
    "sg_client = boto3.client('sagemaker')\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9399b96c",
   "metadata": {},
   "source": [
    "# Creating the SageMaker image\n",
    "\n",
    "The first step is to create an Amazon SageMaker compatible docker image which will run the training.\n",
    "The `container` folder contains both the Dockerfile and the necessary scripts to train and validate the generated model\n",
    "\n",
    "#### During the docker build we will simply clone the yolov5 repository and add the necessary SageMaker scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "064640a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mBASE_IMG\u001b[39;49;00m=\u001b[33m${\u001b[39;49;00m\u001b[31mBASE_IMG\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\n",
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33m${BASE_IMG}\u001b[39;49;00m \n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPATH\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/code:\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mPATH\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[36mcd\u001b[39;49;00m opt && git clone https://github.com/ultralytics/yolov5\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install -r /opt/yolov5/requirements.txt\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPATH\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/yolov5:\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mPATH\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /opt/code\u001b[39;49;00m\n",
      "\u001b[34mCOPY\u001b[39;49;00m train /opt/code\n",
      "\u001b[34mCOPY\u001b[39;49;00m predict /opt/code\n"
     ]
    }
   ],
   "source": [
    "!pygmentize container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7691c70",
   "metadata": {},
   "source": [
    "#### The train script will load the training parameters (more below) and will invoke the yolov5 training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a1e28811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/usr/bin/env python3\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "sys.path.append(\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/yolov5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtrain\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/input/data/config/params.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m params_file:\n",
      "    params = json.load(params_file)\n",
      "    train_params = params[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "\n",
      "opt = train.parse_opt(\u001b[34mTrue\u001b[39;49;00m)\n",
      "\u001b[34mfor\u001b[39;49;00m p \u001b[35min\u001b[39;49;00m train_params:\n",
      "    value = train_params[p]\n",
      "    \u001b[34mif\u001b[39;49;00m value:\n",
      "        \u001b[36msetattr\u001b[39;49;00m(opt, p, value)\n",
      "\n",
      "train.main(opt)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize container/train -l python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d263d59",
   "metadata": {},
   "source": [
    "#### The predict script will also load the parameters and will invoke the yolov5 detect script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d29b31d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/usr/bin/env python3\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "sys.path.append(\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/yolov5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mdetect\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/input/data/config/params.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m params_file:\n",
      "    params = json.load(params_file)\n",
      "    predict_params = params[\u001b[33m'\u001b[39;49;00m\u001b[33mpredict\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "\n",
      "opt = detect.parse_opt()\n",
      "\u001b[34mfor\u001b[39;49;00m p \u001b[35min\u001b[39;49;00m predict_params:\n",
      "    value = predict_params[p]\n",
      "    \u001b[34mif\u001b[39;49;00m value:\n",
      "        \u001b[36msetattr\u001b[39;49;00m(opt, p, value)\n",
      "\n",
      "detect.main(opt)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize container/predict -l python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9ca93",
   "metadata": {},
   "source": [
    "Also, let's inicialize all the necessary clients and get the necessary information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b2d52",
   "metadata": {},
   "source": [
    "## Building the image\n",
    "\n",
    "To build the training image we will use the [PyTorch 1.7.1 SageMaker Deep Learning image](https://github.com/aws/deep-learning-containers/blob/master/available_images.md). \n",
    "\n",
    "To receive this image we will need to login on the SageMaker ECR repository in order to fetch the specific image, more information about this process is available [here](https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-ecs.html).\n",
    "\n",
    "We will also need to create our own private ECR repository and push our image to it after the building process. More information is available [here](https://docs.aws.amazon.com/AmazonECR/latest/userguide/repository-create.html).\n",
    "\n",
    "The entire process is executed below, with comments to help you understanding each step of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f21c8d",
   "metadata": {},
   "source": [
    "We will login on the SageMaker ECR registry to be able to pull the base image, and also on our own ECR to later be able to push our newly generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "f7fce752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in at https://763104351884.dkr.ecr.eu-central-1.amazonaws.com\n",
      "Logged in at https://354767016111.dkr.ecr.eu-central-1.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "response = ecr_client.get_authorization_token(\n",
    "    registryIds=[\n",
    "        SAGEMAKER_IMAGES_REGISTRY_ID,\n",
    "        account_id\n",
    "    ]\n",
    ")\n",
    "\n",
    "for auth in response['authorizationData']:\n",
    "    registry_address = auth['proxyEndpoint']\n",
    "    encoded_token = auth['authorizationToken']\n",
    "    credentials = base64.b64decode(encoded_token).decode('utf-8')\n",
    "    username, password = credentials.split(':')\n",
    "    login = docker_client.login(username, password, registry=registry_address, dockercfg_path='$HOME/.docker/config.json')    \n",
    "    print(f'Logged in at {registry_address}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afbb4fb",
   "metadata": {},
   "source": [
    "#### Now we pull the base image from ECR, this process can take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "825c8bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image: '763104351884.dkr.ecr.eu-central-1.amazonaws.com/pytorch-training:1.7.1-gpu-py36-cu110-ubuntu18.04'>"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_image = f'{SAGEMAKER_IMAGES_REGISTRY_ID}.dkr.ecr.{aws_region}.amazonaws.com/pytorch-training:1.7.1-gpu-py36-cu110-ubuntu18.04'\n",
    "docker_client.images.pull(base_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cecbdd7",
   "metadata": {},
   "source": [
    "#### Before building the image, we will create our own ECR repository and get the URL to push the image later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c42e172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New image will be tagged: 354767016111.dkr.ecr.eu-central-1.amazonaws.com/yolov5-sagemaker\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    repository = ecr_client.describe_repositories(\n",
    "        repositoryNames=[\n",
    "            YOLOV5_IMAGE_NAME,\n",
    "        ]\n",
    "    )['repositories'][0]\n",
    "except:\n",
    "    print('Repository does not exists, creating it')\n",
    "    repository = ecr_client.create_repository(\n",
    "        repositoryName=YOLOV5_IMAGE_NAME\n",
    "    )['repository']\n",
    "    \n",
    "target_image = repository['repositoryUri']\n",
    "print(f'New image will be tagged: {target_image}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d43705",
   "metadata": {},
   "source": [
    "#### And finally, we build the new image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "b58e5589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New image created: ['354767016111.dkr.ecr.eu-central-1.amazonaws.com/yolov5-sagemaker:latest', 'yolov5-sagemaker:latest']\n"
     ]
    }
   ],
   "source": [
    "container_path = f'{pathlib.Path().resolve()}/container'\n",
    "image, build_log = docker_client.images.build(path=container_path, buildargs={'BASE_IMG': base_image}, tag=YOLOV5_IMAGE_NAME)\n",
    "image.tag(target_image, tag='latest')\n",
    "image.reload()\n",
    "print(f'New image created: {image.tags}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b0b38",
   "metadata": {},
   "source": [
    "#### Now we push the recently created image to our ECR registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "4e45cf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The push refers to repository [354767016111.dkr.ecr.eu-central-1.amazonaws.com/yolov5-sagemaker]\n",
      "....\n",
      "latest: digest: sha256:d542b6a1cc4a92ff94553d59a104b8c06ecfab362f1595fbeba6e84124cecb32 size: 8304\n"
     ]
    }
   ],
   "source": [
    "for l in docker_client.images.push(target_image, tag='latest', stream=True, decode=True):\n",
    "    status = l.get('status')\n",
    "    progress = l.get('progressDetail')\n",
    "    if progress == None and status:\n",
    "        print('')\n",
    "        print(status)\n",
    "    elif progress.get('current'):\n",
    "        print('.', end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5c61c",
   "metadata": {},
   "source": [
    "We have our SageMaker image ready to train our model!\n",
    "But first...\n",
    "\n",
    "# Let's prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c241e8",
   "metadata": {},
   "source": [
    "#### First we will download the data and place it on the specific directories\n",
    "\n",
    "The yolov5 weights will be downloaded to `input/weights` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "8c24f4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-16 14:42:59--  https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/264818686/56dd3480-9af3-11eb-9c92-3ecd167961dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210716%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210716T144103Z&X-Amz-Expires=300&X-Amz-Signature=0d9cf988e7e57637b272180b078fd4d63199e45f5ae2e226c1e1eba1b642a850&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-07-16 14:42:59--  https://github-releases.githubusercontent.com/264818686/56dd3480-9af3-11eb-9c92-3ecd167961dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210716%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210716T144103Z&X-Amz-Expires=300&X-Amz-Signature=0d9cf988e7e57637b272180b078fd4d63199e45f5ae2e226c1e1eba1b642a850&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.111.154, 185.199.110.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14795158 (14M) [application/octet-stream]\n",
      "Saving to: ‘input/data/weights/yolov5s.pt’\n",
      "\n",
      "yolov5s.pt          100%[===================>]  14.11M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2021-07-16 14:42:59 (194 MB/s) - ‘input/data/weights/yolov5s.pt’ saved [14795158/14795158]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# weights\n",
    "!wget -P input/data/weights https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e95b8",
   "metadata": {},
   "source": [
    "After that we will download the [coco128 dataset](https://www.kaggle.com/ultralytics/coco128), with the training images and the labels. \n",
    "If you would like to train on your own dataset, you can upload your own images and labels, we will configure the specific data sources on the params file on the upcoming steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "78fbba12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-16 15:29:01--  https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/264818686/7a208a00-e19d-11eb-94cf-5222600cc665?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210716%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210716T152902Z&X-Amz-Expires=300&X-Amz-Signature=e139bed06249f3d7cf5e406256f5e9a9872927d3fe58190567062eaa1bbfc73d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dcoco128.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-07-16 15:29:02--  https://github-releases.githubusercontent.com/264818686/7a208a00-e19d-11eb-94cf-5222600cc665?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210716%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210716T152902Z&X-Amz-Expires=300&X-Amz-Signature=e139bed06249f3d7cf5e406256f5e9a9872927d3fe58190567062eaa1bbfc73d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dcoco128.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.111.154, 185.199.110.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6984509 (6.7M) [application/octet-stream]\n",
      "Saving to: ‘input/data/coco128.zip’\n",
      "\n",
      "coco128.zip         100%[===================>]   6.66M  9.41MB/s    in 0.7s    \n",
      "\n",
      "2021-07-16 15:29:03 (9.41 MB/s) - ‘input/data/coco128.zip’ saved [6984509/6984509]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -rf input/data/images\n",
    "!rm -rf input/data/labels\n",
    "!wget -P input/data https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
    "!unzip -q input/data/coco128.zip 'coco128/labels/*' 'coco128/images/*' -d input/data\n",
    "!mv input/data/coco128/* input/data\n",
    "!rm -rf input/data/coco128*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2cdc34",
   "metadata": {},
   "source": [
    "With the necessary data downloaded (either from coco128 dataset or from your own dataset) the `input` directory will be synced with S3 later, this folder looks like this:\n",
    "```\n",
    "input\n",
    "    |-data\n",
    "    |---config\n",
    "    |-----params.json    \n",
    "    |-----coco128.yaml\n",
    "    |-----hyp.finetune.yaml\n",
    "    |-----yolo5s.yaml    \n",
    "    |---images\n",
    "    |-----train2017\n",
    "    |-------images.jpg\n",
    "    |---labels\n",
    "    |-----train2017\n",
    "    |-------labels.txt\n",
    "    |---weights\n",
    "    |-----yolo5s.pt\n",
    "    \n",
    "```\n",
    "\n",
    "The `input/config` folder contains contains the [training dataset configurations](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml) (coco128.yaml), the [hyperparameters for model training](https://github.com/ultralytics/yolov5/issues/607) (hyp.finetune.yaml) and the [model configuration itself](https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml) (yolo5s.yaml).\n",
    "\n",
    "You can adjust those files as you wish, the links above provide more information regarding each file.\n",
    "\n",
    "You can also add new files with diferent naming convention, those inputs will be configured on the `input/data/config/params.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "36ca6e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \u001b[94m\"train\"\u001b[39;49;00m: {\n",
      "    \u001b[94m\"weights\"\u001b[39;49;00m: \u001b[33m\"/opt/ml/input/data/weights/yolov5s.pt\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"cfg\"\u001b[39;49;00m: \u001b[33m\"/opt/ml/input/data/config/yolo5s.yaml\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"data\"\u001b[39;49;00m: \u001b[33m\"/opt/ml/input/data/config/coco128.yml\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"hyp\"\u001b[39;49;00m: \u001b[33m\"/opt/ml/input/data/config/hyp.finetune.yaml\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"epochs\"\u001b[39;49;00m: \u001b[34m300\u001b[39;49;00m,\n",
      "    \u001b[94m\"batch_size\"\u001b[39;49;00m: \u001b[34m16\u001b[39;49;00m,\n",
      "    \u001b[94m\"img_size\"\u001b[39;49;00m: [\u001b[34m640\u001b[39;49;00m, \u001b[34m640\u001b[39;49;00m],\n",
      "    \u001b[94m\"rect\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"resume\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"nosave\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"noval\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"noautoanchor\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"evolve\"\u001b[39;49;00m: \u001b[33m\"\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"bucket\"\u001b[39;49;00m: \u001b[33m\"\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"cache_images\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"image_weights\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"device\"\u001b[39;49;00m: \u001b[33m\"\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"multi_scale\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"single_cls\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"adam\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"sync_bn\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"workers\"\u001b[39;49;00m: \u001b[34m20\u001b[39;49;00m,\n",
      "    \u001b[94m\"project\"\u001b[39;49;00m: \u001b[33m\"/opt/ml/model\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"entity\"\u001b[39;49;00m: \u001b[33m\"\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"name\"\u001b[39;49;00m: \u001b[33m\"exp\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"exist_ok\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"quad\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"linear_lr\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"label_smoothing\"\u001b[39;49;00m: \u001b[34m0.0\u001b[39;49;00m,\n",
      "    \u001b[94m\"upload_dataset\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"bbox_interval\"\u001b[39;49;00m: \u001b[34m-1\u001b[39;49;00m,\n",
      "    \u001b[94m\"save_period\"\u001b[39;49;00m: \u001b[34m-1\u001b[39;49;00m,\n",
      "    \u001b[94m\"artifact_alias\"\u001b[39;49;00m: \u001b[33m\"latest\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"local_rank\"\u001b[39;49;00m: \u001b[34m-1\u001b[39;49;00m\n",
      "  },\n",
      "  \u001b[94m\"predict\"\u001b[39;49;00m: {\n",
      "    \u001b[94m\"agnostic_nms\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"augment\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"classes\"\u001b[39;49;00m: \u001b[33m\"\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"conf_thres\"\u001b[39;49;00m: \u001b[34m0.25\u001b[39;49;00m,\n",
      "    \u001b[94m\"device\"\u001b[39;49;00m: \u001b[33m\"\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"exist_ok\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"half\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"hide_conf\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"hide_labels\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"imgsz\"\u001b[39;49;00m: \u001b[34m640\u001b[39;49;00m,\n",
      "    \u001b[94m\"iou_thres\"\u001b[39;49;00m: \u001b[34m0.45\u001b[39;49;00m,\n",
      "    \u001b[94m\"line_thickness\"\u001b[39;49;00m: \u001b[34m3\u001b[39;49;00m,\n",
      "    \u001b[94m\"max_det\"\u001b[39;49;00m: \u001b[34m1000\u001b[39;49;00m,\n",
      "    \u001b[94m\"name\"\u001b[39;49;00m: \u001b[33m\"exp\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"nosave\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"project\"\u001b[39;49;00m: \u001b[33m\"/opt/ml/model\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"save_conf\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"save_crop\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"save_txt\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"source\"\u001b[39;49;00m: \u001b[33m\"/opt/ml/input/data/train/images/predict\"\u001b[39;49;00m,\n",
      "    \u001b[94m\"update\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"view_img\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"visualize\"\u001b[39;49;00m: \u001b[34mfalse\u001b[39;49;00m,\n",
      "    \u001b[94m\"weights\"\u001b[39;49;00m: \u001b[33m\"/opt/ml/input/data/weights/yolov5s.pt\"\u001b[39;49;00m\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!pygmentize input/data/config/params.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974b24d",
   "metadata": {},
   "source": [
    "This file contains all the input configurations used to both, train and predict the model inside the SageMaker container. You can edit this file on your S3 at any point in time, and just need to run your training job again.\n",
    "\n",
    "With the local folder structure ready, let's sync this with the S3 bucket we will use during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "d8e8883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be placed at s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/input/\n"
     ]
    }
   ],
   "source": [
    "s3_path = utils.name_from_base(MODEL_BASE_NAME)\n",
    "\n",
    "sg_exec_role = get_execution_role()\n",
    "sg_session = Session()\n",
    "s3_region = sg_session.boto_region_name\n",
    "sg_bucket = sg_session.default_bucket()\n",
    "s3_input_destination = f's3://{sg_bucket}/{s3_path}/input/'\n",
    "s3_output_destination = f's3://{sg_bucket}/{s3_path}/output/'\n",
    "print(f'Data will be placed at {s3_input_destination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "2e91233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/input/\n",
      "                           PRE data/\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$s3_input_destination\"\n",
    "aws s3 sync ./input $1 --quiet\n",
    "echo \"$1\"\n",
    "aws s3 ls \"$1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4397141",
   "metadata": {},
   "source": [
    "with the data in place and the docker image saved on our ECR...\n",
    "\n",
    "# Let's Start the training job\n",
    "\n",
    "To run the SageMaker training job we will need to pass some parameters. The first is the [InputDataConfig](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html#API_CreateTrainingJob_RequestParameters).\n",
    "\n",
    "We will use a series of [SageMaker Channels](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_Channel.html) to map our S3 folders to the SageMaker training image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "575d8f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration will be fetched from: s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/input/data/config/\n",
      "Images will be fetched from: s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/input/data/images/\n",
      "Labels will be fetched from: s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/input/data/labels/\n",
      "Weights will be fetched from: s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/input/data/weights/\n",
      "Output will be placed at: s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/output/\n"
     ]
    }
   ],
   "source": [
    "config_channel_src = f'{s3_input_destination}data/config/'\n",
    "images_channel_src = f'{s3_input_destination}data/images/'\n",
    "labels_channels_src= f'{s3_input_destination}data/labels/'\n",
    "weights_channel_src = f'{s3_input_destination}data/weights/'\n",
    "\n",
    "print('Configuration will be fetched from:', config_channel_src)\n",
    "print('Images will be fetched from:', images_channel_src)\n",
    "print('Labels will be fetched from:', labels_channels_src)\n",
    "print('Weights will be fetched from:', weights_channel_src)\n",
    "print('Output will be placed at:', s3_output_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e8665",
   "metadata": {},
   "source": [
    "Let's look how our input channels look like on S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4245b514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/input/data/config/\n",
      "                           PRE .ipynb_checkpoints/\n",
      "2021-07-16 15:30:20       1061 coco128.yml\n",
      "2021-07-16 15:29:48        861 hyp.finetune.yaml\n",
      "2021-07-16 15:41:02       1556 params.json\n",
      "2021-07-16 15:29:48       1454 yolo5s.yaml\n",
      "\n",
      "s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/input/data/images/\n",
      "                           PRE train2017/\n",
      "2021-07-16 15:29:48       6148 .DS_Store\n",
      "\n",
      "s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/input/data/labels/\n",
      "                           PRE train2017/\n",
      "2021-07-16 15:29:49       6148 .DS_Store\n",
      "\n",
      "s3://sagemaker-eu-central-1-354767016111/yolov5-2021-07-16-15-29-43-562/input/data/weights/\n",
      "2021-07-16 15:29:49   14795158 yolov5s.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$config_channel_src\" \"$images_channel_src\" \"$labels_channels_src\" \"$weights_channel_src\"\n",
    "for b in \"$@\"; do\n",
    "    echo \"$b\"\n",
    "    aws s3 ls \"$b\"\n",
    "    echo ''\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b019f31",
   "metadata": {},
   "source": [
    "With everything in place, let's submit the training job to SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "57c381b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainingJobArn': 'arn:aws:sagemaker:eu-central-1:354767016111:training-job/yolov5-2021-07-16-15-41-21-527',\n",
       " 'ResponseMetadata': {'RequestId': '409b0200-bdac-419b-b545-50d7fc9a5b07',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '409b0200-bdac-419b-b545-50d7fc9a5b07',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '108',\n",
       "   'date': 'Fri, 16 Jul 2021 15:41:21 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = utils.name_from_base(MODEL_BASE_NAME)\n",
    "submited_job = sg_client.create_training_job(\n",
    "      TrainingJobName=job_name,\n",
    "      AlgorithmSpecification={\n",
    "          'TrainingImage': target_image,\n",
    "          'TrainingInputMode': 'File',\n",
    "      },\n",
    "      RoleArn=sg_exec_role,\n",
    "      InputDataConfig=[\n",
    "          {\n",
    "              'ChannelName': 'config',\n",
    "              'DataSource': {\n",
    "                  'S3DataSource': {\n",
    "                      'S3DataType': 'S3Prefix',\n",
    "                      'S3Uri': config_channel_src,\n",
    "                      'S3DataDistributionType': 'FullyReplicated',\n",
    "                  },\n",
    "              },\n",
    "              'InputMode': 'File'\n",
    "          },\n",
    "          {\n",
    "              'ChannelName': 'images',\n",
    "              'DataSource': {\n",
    "                  'S3DataSource': {\n",
    "                      'S3DataType': 'S3Prefix',                      \n",
    "                      'S3Uri': images_channel_src,\n",
    "                      'S3DataDistributionType': 'FullyReplicated',\n",
    "                  },\n",
    "              },\n",
    "              'InputMode': 'File'\n",
    "          },\n",
    "          {\n",
    "              'ChannelName': 'labels',\n",
    "              'DataSource': {\n",
    "                  'S3DataSource': {\n",
    "                      'S3DataType': 'S3Prefix',                      \n",
    "                      'S3Uri': labels_channels_src,\n",
    "                      'S3DataDistributionType': 'FullyReplicated',\n",
    "                  },\n",
    "              },\n",
    "              'InputMode': 'File'\n",
    "          },\n",
    "          {\n",
    "              'ChannelName': 'weights',\n",
    "              'DataSource': {\n",
    "                  'S3DataSource': {\n",
    "                      'S3DataType': 'S3Prefix',                      \n",
    "                      'S3Uri': weights_channel_src,\n",
    "                      'S3DataDistributionType': 'FullyReplicated',\n",
    "                  },\n",
    "              },\n",
    "              'InputMode': 'File'\n",
    "          }\n",
    "      ],\n",
    "      OutputDataConfig={\n",
    "          'S3OutputPath': s3_output_destination\n",
    "      },\n",
    "      ResourceConfig={\n",
    "          'InstanceType': 'ml.p3.2xlarge',\n",
    "          'InstanceCount': 1,\n",
    "          'VolumeSizeInGB': 10,\n",
    "      },\n",
    "      StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 60*60*5,\n",
    "      }\n",
    "  )\n",
    "submited_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fe0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting job to finish:\n",
      "Starting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Downloading . . . . . . \n",
      "Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . "
     ]
    }
   ],
   "source": [
    "print('Waiting job to finish:', end='')\n",
    "running = True\n",
    "previous_status = ''\n",
    "while running:\n",
    "    job_status = sg_client.describe_training_job(\n",
    "        TrainingJobName=job_name\n",
    "    )\n",
    "    running = job_status['TrainingJobStatus'] == 'InProgress'\n",
    "    current_status = job_status['SecondaryStatus']\n",
    "    if previous_status != current_status:\n",
    "        print('')\n",
    "        print(f'{current_status} ', end='')\n",
    "        previous_status = current_status\n",
    "    print('. ', end='')\n",
    "    time.sleep(1)\n",
    "\n",
    "print('')\n",
    "final_status = job_status['TrainingJobStatus']\n",
    "if final_status == 'Failed':\n",
    "    print(f'Job Failed!: {job_status[\"FailureReason\"]}')\n",
    "else:\n",
    "    print(f'Job Finished! {final_status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda6869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
